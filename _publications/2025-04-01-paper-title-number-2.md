---
title: "Layer-wise regularized adversarial training using layers sustainability analysis framework"
collection: publications
category: manuscripts
permalink: /publication/2015-02
excerpt: 'Deep neural network models are used today in various applications of artificial intelligence, the strengthening of which, in the face of adversarial attacks is of particular importance. An appropriate solution to adversarial attacks is adversarial training, which reaches a trade-off between robustness and generalization. This paper introduces a novel framework (Layer Sustainability Analysis (LSA)) for the analysis of layer vulnerability in an arbitrary neural network in the scenario of adversarial attacks. LSA can be a helpful toolkit to assess deep neural networks and to extend the adversarial training approaches towards improving the sustainability of model layers via layer monitoring and analysis. The LSA framework identifies a list of Most Vulnerable Layers (MVL list) of the given network. The relative error, as a comparison measure, is used to evaluate representation sustainability of each layer against adversarial inputs â€¦'
date: 2023-09-10
venue: 'Neurocomputing'
slidesurl: 'https://www.sciencedirect.com/science/article/abs/pii/S0925231223002928'
paperurl: 'https://www.sciencedirect.com/science/article/abs/pii/S0925231223002928'
bibtexurl: 'https://www.sciencedirect.com/science/article/abs/pii/S0925231223002928'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

# Highlights

* The layer sustainability analysis (LSA) framework is introduced to evaluate the behavior of layer-level representations of DNNs in dealing with network input perturbations using Lipschitz theoretical concepts.
* A layer-wise regularized adversarial training (AT-LR) approach significantly improves the generalization and robustness of different deep neural network architectures for significant perturbations while reducing layer-level vulnerabilities.
* AT-LR loss landscapes for each LSA MVL proposal can interpret layer importance for different layers, which is an intriguing aspect.
